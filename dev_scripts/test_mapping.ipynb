{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b79121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b14c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_MODEL = SentenceTransformer(\"models/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_str(s):\n",
    "    s = re.sub('<s>', '', s)\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "def process_ts_section(section):\n",
    "    ''' clean parsed term in TS\n",
    "    '''\n",
    "    processed_section = ''\n",
    "    try:\n",
    "        processed_section = process_str(re.split('  ', section)[0])\n",
    "    except Exception as e:\n",
    "        print(section, e)\n",
    "    return processed_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(\n",
    "    ts_string_list,\n",
    "    fa_string_list,\n",
    "    map_type,\n",
    "    sim_threshold=0.6,\n",
    "    model_path='models/all-MiniLM-L6-v2',\n",
    "    pretrained=None,\n",
    "    top_N=5\n",
    "):\n",
    "    from sentence_transformers import SentenceTransformer, util\n",
    "    import torch\n",
    "    \n",
    "#     if pretrained is not None:\n",
    "#         model = SentenceTransformer(pretrained, device=torch.device(\"cuda\", 2))\n",
    "#     else:\n",
    "#         model = SentenceTransformer(model_path, device=torch.device(\"cuda\", 2))\n",
    "    model = SentenceTransformer(model_path)\n",
    "        \n",
    "    embeddings1 = model.encode(ts_string_list, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(fa_string_list, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    \n",
    "    similar_pairs = {}\n",
    "    for i in range(len(ts_string_list)):\n",
    "        all_score = list(cosine_scores[i])\n",
    "        above_threshold_idx = [all_score.index(k) for k in [j for j in all_score if j >= sim_threshold]]\n",
    "        above_threshold_sims = [j.item() for j in all_score if j >= sim_threshold]\n",
    "        idx_sims = list(zip(above_threshold_idx, above_threshold_sims))\n",
    "\n",
    "        idx_sims = sorted(idx_sims, key=lambda x: x[1], reverse=True)[:top_N]\n",
    "        ref_string = []\n",
    "#         sim_score = []\n",
    "        \n",
    "        map_results = []\n",
    "        for idx, sims in idx_sims:\n",
    "            string = fa_string_list[idx]\n",
    "            if string not in ref_string:\n",
    "                ref_string.append(string)\n",
    "                map_results.append({\n",
    "                    'similar_term': string,\n",
    "                    'score': round(sims, 2),\n",
    "                    'map_type': map_type\n",
    "                })\n",
    "        if ref_string:\n",
    "            similar_pairs.update({\n",
    "                ts_string_list[i]: map_results\n",
    "            })\n",
    "    return similar_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db95a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612a9d69",
   "metadata": {},
   "source": [
    "# Read TS & FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84026c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_file = \"data/docparse_csv_annotated/annotated/1_GL_SYN_TS_mkd_20221215_docparse.csv\"\n",
    "# ts_file = \"data/join_label/13_BL_SYN_TS_mkd_20220713_docparse.csv\"\n",
    "fa_file = \"data/docparse_csv/FA/1_GL_SYN_FA_mkd_20221215_docparse.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55383b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FA file\n",
    "df_fa = pd.read_csv(fa_file)\n",
    "# parties\n",
    "isPartiesStart = df_fa.text.str.contains('^THIS AGREEMENT is|is made on|^PARTIES|Between:*', na=False, case=False)\n",
    "isPartiesEnd = df_fa.text.str.contains('AGREED* as follows|AGREED* that', na=False, case=False)\n",
    "partiesBeginID = df_fa[isPartiesStart]['index'].values[0] + 1\n",
    "partiesEndID = df_fa[isPartiesEnd]['index'].values[0] - 1\n",
    "parties_clause_id = df_fa['index'].between(isPartiesStart, isPartiesEnd)\n",
    "df_fa.loc[parties_clause_id,'section'] = 'PARTIES'\n",
    "df_fa.loc[parties_clause_id, 'section_id'] = '0'\n",
    "\n",
    "df_parties = df_fa[(df_fa.section_id == \"0\") | (df_fa.section_id == 0)] # cols: definition + text\n",
    "# definition\n",
    "df_def = df_fa[\n",
    "    (df_fa.section == \"DEFINITIONS AND INTERPRETATION\")&(df_fa.sub_section == \"Definitions\")\n",
    "] # cols: definition + text\n",
    "df_def = df_def[~df_def.definition.isna()]\n",
    "# exclude parties & definition clause\n",
    "df_others = df_fa[\n",
    "    (df_fa.section != \"DEFINITIONS AND INTERPRETATION\") & (df_fa.section  != \"PARTIES\")\n",
    "]\n",
    "# schedule\n",
    "df_schedule = df_others.loc[df_others.schedule.notnull()]\n",
    "# main clause\n",
    "df_clause = df_others.loc[~df_others.schedule.notnull()]\n",
    "#df_clause = df_clause[(df_clause.text_element != \"section\") & (df_clause.text_element != \"sub_section\")]\n",
    "\n",
    "\n",
    "# TS file\n",
    "df_ts = pd.read_csv(ts_file)\n",
    "df_ts[\"processed_section\"] = df_ts[\"section\"].apply(\n",
    "    lambda i: process_ts_section(i)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c715db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedule.part.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ts.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df_ts.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284107b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df_ts.procesdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3136f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_ts.processed_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec0e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\n",
    "    df_ts[df_ts.text_element=='section']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65202315",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_fa), len(df_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab3d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "081d9714",
   "metadata": {},
   "source": [
    "# Term Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22593c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS term section vs. FA definition\n",
    "\n",
    "top_N = 5\n",
    "\n",
    "ts_section_list = list(set(df_ts.processed_section))\n",
    "ts_section_list = [s for s in ts_section_list if s]\n",
    "\n",
    "def_string_list = list(set(df_def.definition))\n",
    "def_string_list = [s for s in def_string_list if s]\n",
    "\n",
    "\n",
    "pairs_def = dict()\n",
    "if def_string_list:\n",
    "    pairs_def = get_similarity(\n",
    "        ts_section_list,\n",
    "        def_string_list,\n",
    "        \"sec_to_def\",\n",
    "        sim_threshold=0.9\n",
    "    )\n",
    "else:\n",
    "    print(f, 'Check: No definition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a69f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4802394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the final results & compare with the raw sections\n",
    "\n",
    "df_results = pd.read_csv('data/term_matching_csv/20230718/2_GF_SYN_TS_mkd_20221111_docparse_results.csv')\n",
    "for item in ts_section_list:\n",
    "    if item not in list(set(df_results.TS_term)):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac7526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS term section vs. FA parties\n",
    "parties_string_list = []\n",
    "for s in list(set(df_parties.definition)):\n",
    "    if s:\n",
    "        if s not in parties_string_list:\n",
    "            if isinstance(s, str):\n",
    "                parties_string_list.append(s)\n",
    "\n",
    "pairs_parties = dict()\n",
    "if parties_string_list:\n",
    "    pairs_parties = get_similarity(\n",
    "        ts_section_list,\n",
    "        parties_string_list,\n",
    "        \"sec_to_parties\",\n",
    "        sim_threshold=0.5\n",
    "    )\n",
    "else:\n",
    "    print('Check: No parties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs_parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b6352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS term v.s. FA sub section\n",
    "sub_sec_list = list(set(df_clause[df_clause.text_element == \"sub_section\"].sub_section))\n",
    "sub_sec_list = [s for s in sub_sec_list if s]\n",
    "pairs_sec_to_sub_sec = get_similarity(\n",
    "    ts_section_list,\n",
    "    sub_sec_list,\n",
    "    \"sec_to_sub_sec\",\n",
    "    sim_threshold=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs_sec_to_sub_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c15f69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pairs_sec_to_sub_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237fa6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS term + text vs. FA clause\n",
    "clause_section_list = list(set(df_clause[df_clause.text_element == \"section\"].section))\n",
    "clause_section_list = [s for s in clause_section_list if s]\n",
    "# TS section v.s. FA clause section -> select potential FA clause section\n",
    "pairs_clause_section = get_similarity(\n",
    "    ts_section_list,\n",
    "    clause_section_list,\n",
    "    \"clause_section\",\n",
    "    sim_threshold=0.3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c04606",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs_clause_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c193d6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k, v in pairs_clause_section.items():\n",
    "#     print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2be191c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_pairs_clause = []\n",
    "# pairs_sec_to_sub_sec = dict()\n",
    "# check under the section candidates\n",
    "for k, v in pairs_clause_section.items():\n",
    "    df_ts_sub = df_ts[df_ts.processed_section == k]\n",
    "    ts_text_list = [] # process nan value\n",
    "    for s in list(set(df_ts_sub[df_ts_sub.text_element!='section'].text)):\n",
    "        if s:\n",
    "            if s not in ts_text_list:\n",
    "                if isinstance(s, str):\n",
    "                    ts_text_list.append(s)\n",
    "    \n",
    "    \n",
    "    ts_section_list = list(set(df_ts_sub.processed_section))\n",
    "\n",
    "    candidates = [item['similar_term'] for item in v]\n",
    "    df_clause_sub = df_clause[df_clause.section.isin(candidates)]\n",
    "    print(k, len(df_ts_sub), len(ts_text_list), len(df_clause_sub))\n",
    "\n",
    "    sub_section_list = [] # process nan value\n",
    "    for s in list(set(df_clause_sub[df_clause_sub.text_element == \"sub_section\"].sub_section)):\n",
    "        if s:\n",
    "            if s not in sub_section_list:\n",
    "                if isinstance(s, str):\n",
    "                    sub_section_list.append(s)\n",
    "    \n",
    "    clause_string_list = list(set(\n",
    "        df_clause_sub[(df_clause_sub.text_element != \"section\") & (df_clause_sub.text_element != \"sub_section\")].text\n",
    "    ))\n",
    "\n",
    "    pairs_sub_section = dict()\n",
    "    pairs_sec_to_sub_sec_partial = dict()\n",
    "    if sub_section_list:\n",
    "        if ts_text_list:\n",
    "            pairs_sub_section = get_similarity(\n",
    "                ts_text_list,\n",
    "                sub_section_list,\n",
    "                \"text_to_sub_sec\",\n",
    "                sim_threshold=0\n",
    "            )\n",
    "        else:\n",
    "            print('no text in ', k)\n",
    "        pairs_sec_to_sub_sec_partial = get_similarity(\n",
    "            ts_section_list,\n",
    "            sub_section_list,\n",
    "            \"sec_to_sub_sec\",\n",
    "            sim_threshold=0\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print('no sub sectin in ', k)\n",
    "    pairs_sec_to_sub_sec.update(pairs_sec_to_sub_sec_partial)\n",
    "    pairs_clause = dict()\n",
    "    if ts_text_list and clause_string_list:\n",
    "        pairs_clause = get_similarity(\n",
    "            ts_text_list,\n",
    "            clause_string_list,\n",
    "            \"text_to_clause_text\",\n",
    "            sim_threshold=0\n",
    "        )\n",
    "\n",
    "    if pairs_sub_section:\n",
    "        total_pairs_clause.append({\n",
    "            k: pairs_sub_section\n",
    "        })\n",
    "    if pairs_clause:\n",
    "        total_pairs_clause.append({k: pairs_clause})\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c1a4a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(total_pairs_clause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2e6223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('data/term_matching_csv/json/total_pairs_clause.json', 'w') as f:\n",
    "#     json.dump(total_pairs_clause, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432a13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### add TS term + text vs. FA schedule\n",
    "# TODO: use the whole schedule or the details?\n",
    "# 0729: add \"part\" in schedule; TS term vs. FA schedule part\n",
    "\n",
    "schedule_section_list = list(set(df_schedule.schedule))\n",
    "schedule_part_list = list(set(df_schedule.part))\n",
    "schedule_part_list = [p for p in schedule_part_list if p]\n",
    "\n",
    "pairs_schedule_section = dict()\n",
    "if schedule_section_list:\n",
    "    pairs_schedule_section = get_similarity(\n",
    "        ts_section_list,\n",
    "        schedule_section_list,\n",
    "        \"schedule_section\"\n",
    "    )\n",
    "else:\n",
    "    print('No schedule section')\n",
    "\n",
    "if schedule_part_list:\n",
    "    pairs_schedule_part = get_similarity(\n",
    "        ts_section_list,\n",
    "        schedule_part_list,\n",
    "        \"schedule_part\",\n",
    "        sim_threshold=0\n",
    "    )\n",
    "\n",
    "\n",
    "total_pairs_sched = []\n",
    "# check under the section candidates\n",
    "for k, v in pairs_schedule_section.items():\n",
    "    df_ts_sub = df_ts[df_ts.processed_section == k]\n",
    "    s_text_list = list(set(df_ts_sub[df_ts_sub.text_element!='section'].text))\n",
    "    \n",
    "    candidates = [item['similar_term'] for item in v]\n",
    "    df_sched_sub = df_schedule[df_schedule.schedule.isin(candidates)]\n",
    "    sched_text_list = list(set(df_sched_sub.text))\n",
    "    pairs_sched = dict()\n",
    "    print(len(ts_text_list), len(sched_text_list))\n",
    "    if ts_text_list and sched_text_list:\n",
    "        pairs_sched = get_similarity(\n",
    "            ts_text_list,\n",
    "            sched_text_list,\n",
    "            \"text_to_schedule_text\",\n",
    "            sim_threshold=0\n",
    "        )\n",
    "    if pairs_sched:\n",
    "        total_pairs_sched.append({k: pairs_sched})\n",
    "    print(k, len(df_ts_sub), len(ts_text_list), len(df_sched_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_pairs_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd92be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize all results\n",
    "\n",
    "df_ts['similar_def'] = df_ts['processed_section'].apply(\n",
    "    lambda i: pairs_def.get(i)\n",
    ")\n",
    "df_ts['similar_parties'] = df_ts['processed_section'].apply(\n",
    "    lambda i: pairs_parties.get(i)\n",
    ")\n",
    "df_ts['similar_sub_section'] = df_ts['processed_section'].apply(\n",
    "    lambda i: pairs_sec_to_sub_sec.get(i)\n",
    ")\n",
    "df_ts['similar_schedule'] = df_ts['processed_section'].apply(\n",
    "    lambda i: pairs_schedule_part.get(i)\n",
    ")\n",
    "\n",
    "df_ts_def = df_ts[~df_ts.similar_def.isna()][['section', 'processed_section', 'text','similar_def']]\n",
    "df_ts_parties = df_ts[~df_ts.similar_parties.isna()][['section', 'processed_section',  'text','similar_parties']]\n",
    "df_ts_sub_sec = df_ts[~df_ts.similar_sub_section.isna()][['section', 'processed_section',  'text', 'similar_sub_section']]\n",
    "df_ts_sched = df_ts[~df_ts.similar_schedule.isna()][['section', 'processed_section',  'text', 'similar_schedule']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check\n",
    "total_pairs = []\n",
    "\n",
    "for sec in list(set(df_ts_def.processed_section)):\n",
    "    sub_df = df_ts_def[df_ts_def.processed_section==sec]\n",
    "    total_pairs.append({\n",
    "        sec: dict(zip(sub_df.text, sub_df.similar_def))\n",
    "    })\n",
    "\n",
    "for sec in list(set(df_ts_parties.processed_section)):\n",
    "    sub_df = df_ts_parties[df_ts_parties.processed_section==sec]\n",
    "    total_pairs.append({\n",
    "        sec: dict(zip(sub_df.text, sub_df.similar_parties))\n",
    "    })\n",
    "\n",
    "for sec in list(set(df_ts_sub_sec.processed_section)):\n",
    "    sub_df = df_ts_sub_sec[df_ts_sub_sec.processed_section==sec]\n",
    "    total_pairs.append({\n",
    "        sec: dict(zip(sub_df.text, sub_df.similar_sub_section))\n",
    "    })\n",
    "for sec in list(set(df_ts_sched.processed_section)):\n",
    "    sub_df = df_ts_sched[df_ts_sched.processed_section==sec]\n",
    "    total_pairs.append({\n",
    "        sec: dict(zip(sub_df.text, sub_df.similar_schedule))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pairs.extend(total_pairs_clause)\n",
    "total_pairs.extend(total_pairs_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4df0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/term_matching_csv/json/total_pairs.json', 'w') as f:\n",
    "#     json.dump(total_pairs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remark():\n",
    "    ''' \n",
    "    pairs_xx = {\n",
    "        term1: [{'similar_term': '', 'score': '', 'map_type': ''},...],\n",
    "        term2: [{'similar_term': '', 'score': '', 'map_type': ''},...],\n",
    "        ...\n",
    "    }\n",
    "    \n",
    "    \n",
    "    total_pairs_clause = [\n",
    "        {\n",
    "            term1: {\n",
    "                text11: [{'similar_term': '', 'score': '', 'map_type': ''},...],\n",
    "                text12: [{'similar_term': '', 'score': '', 'map_type': ''},...],\n",
    "                ...\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            term2: {\n",
    "                text21: [{'similar_term': '', 'score': '', 'map_type': ''},...],\n",
    "                text22: [{'similar_term': '', 'score': '', 'map_type': ''},...],\n",
    "                ...\n",
    "            },\n",
    "        }\n",
    "        ...\n",
    "    ]\n",
    "    final format -> total_pairs_clause\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "keys = []\n",
    "for pair in total_pairs:\n",
    "    k = list(pair.keys())[0]\n",
    "    if k not in keys:\n",
    "        keys.append(k)\n",
    "\n",
    "\n",
    "total_pairs_updated = []\n",
    "for k in keys:\n",
    "    sub_pairs = [p[k] for p in total_pairs if list(p.keys())[0] == k]\n",
    "    dd = defaultdict(list)\n",
    "    for p in sub_pairs:\n",
    "        for i, j in p.items():\n",
    "            dd[i].extend(j)\n",
    "    \n",
    "    total_pairs_updated.append({k: dd})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/term_matching_csv/json/total_pairs_updated.json', 'w') as f:\n",
    "#     json.dump(total_pairs_updated, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for pair in total_pairs_updated:\n",
    "    for sec, value in pair.items():\n",
    "        for text, match in value.items():\n",
    "            for item in match:\n",
    "                results.append({\n",
    "                    'TS_section': sec,\n",
    "                    'TS_text': text,\n",
    "                    'match_term': item['similar_term'],\n",
    "                    'similarity': item['score'],\n",
    "                    'match_type': item['map_type']\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_results = pd.DataFrame(data=results)\n",
    "df_results = df_results.drop_duplicates()\n",
    "print(len(df_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.sort_values(by=['TS_text', 'similarity'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.match_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb57ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map TS basic information\n",
    "ts_map = {}\n",
    "for idx, row in df_ts[['index','text_block_id','page_id', 'section','processed_section','text']].drop_duplicates().iterrows():\n",
    "    ts_map[row['text']] = [\n",
    "        row['index'],\n",
    "        row['text_block_id'],\n",
    "        row['page_id'],\n",
    "        # row['phrase_id']\n",
    "        # row['section']\n",
    "    ]\n",
    "\n",
    "content2id = {\n",
    "    'sec_to_def': dict(),\n",
    "    'text_to_clause_text': dict(),\n",
    "    'text_to_sub_sec': dict(),\n",
    "    'text_to_schedule_text': dict(),\n",
    "    'sec_to_parties': dict(),\n",
    "    'sec_to_sub_sec': dict()\n",
    "}\n",
    "\n",
    "for idx, row in df_def[['definition', 'identifier']].drop_duplicates().iterrows():\n",
    "    content2id['sec_to_def'].update({row['definition']: row['identifier']})\n",
    "\n",
    "for idx, row in df_fa[df_fa.text_element=='sub_section'][['sub_section', 'identifier']].drop_duplicates().iterrows():\n",
    "    content2id['text_to_sub_sec'].update({row['sub_section']: row['identifier']})\n",
    "content2id['sec_to_sub_sec'] = content2id['text_to_sub_sec']\n",
    "for idx, row in df_clause[['text', 'identifier']].drop_duplicates().iterrows():\n",
    "    content2id['text_to_clause_text'].update({row['text']: row['identifier']})\n",
    "\n",
    "\n",
    "for idx, row in df_schedule[['text', 'identifier']].drop_duplicates().iterrows():\n",
    "    content2id['text_to_schedule_text'].update({row['text']: row['identifier']})\n",
    "\n",
    "for idx, row in df_parties[['definition', 'identifier']].drop_duplicates().iterrows():\n",
    "    content2id['sec_to_parties'].update({row['definition']: row['identifier']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['identifier'] = df_results.apply(\n",
    "    lambda i: content2id[i['match_type']].get(i['match_term']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_results['index'] = df_results.apply(\n",
    "    lambda i: ts_map.get(i['TS_text'])[0],\n",
    "    axis=1\n",
    ")\n",
    "df_results['text_block_id'] = df_results.apply(\n",
    "    lambda i: ts_map.get(i['TS_text'])[1],\n",
    "    axis=1\n",
    ")\n",
    "df_results['page_id'] = df_results.apply(\n",
    "    lambda i: ts_map.get(i['TS_text'])[2],\n",
    "    axis=1\n",
    ")\n",
    "# df_results['phrase_id'] = df_results.apply(\n",
    "#     lambda i: ts_map.get(i['TS_text'])[3],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "df_results = df_results.sort_values(\n",
    "    by=['TS_section', 'TS_text', 'similarity'],\n",
    "    ascending=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9822c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_results) # 2924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results.TS_section=='FATCA Clauses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.TS_section.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8739026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results.to_csv('results_2_20230710.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475bd3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3be1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in os.listdir('data/term_matching_csv/20230712/check/'):\n",
    "    print(f)\n",
    "    df_results = pd.read_csv(f'data/term_matching_csv/20230712/check/{f}')\n",
    "    final = []\n",
    "\n",
    "    for term in list(set(df_results.TS_section)):\n",
    "        df_s = df_results[df_results.TS_section==term]\n",
    "        for text in list(set(df_s.TS_text)):\n",
    "            df_ss = df_s[df_s.TS_text==text]\n",
    "            try:\n",
    "                final.append({\n",
    "                    'index': list(df_ss['index'])[0],\n",
    "                    'text_block_id': list(df_ss['text_block_id'])[0],\n",
    "                    'page_id': list(df_ss['page_id'])[0],\n",
    "                    'phrase_id': list(df_ss['phrase_id'])[0],\n",
    "                    'TS_term': term,\n",
    "                    'TS_text': text,\n",
    "                    'match_term_list': list(df_ss['match_term'])[:5],\n",
    "                    'identifier_list': list(df_ss['identifier'])[:5],\n",
    "                    'similarity_list': list(df_ss['similarity'])[:5],\n",
    "                    'match_type_list': list(df_ss['match_type'])[:5]\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(term, text, e)\n",
    "    df_final = pd.DataFrame(data=final)\n",
    "    save_file = re.sub('.csv', '_results.csv', f)\n",
    "    df_final.to_csv(f'data/term_matching_csv/20230712/new/{save_file}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8907e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "\n",
    "for term in list(set(df_results.TS_section)):\n",
    "    df_s = df_results[df_results.TS_section==term]\n",
    "    for text in list(set(df_s.TS_text)):\n",
    "        df_ss = df_s[df_s.TS_text==text]\n",
    "        try:\n",
    "            final.append({\n",
    "                'index': list(df_ss['index'])[0],\n",
    "                'text_block_id': list(df_ss['text_block_id'])[0],\n",
    "                'page_id': list(df_ss['page_id'])[0],\n",
    "                'TS_term': term,\n",
    "                'TS_text': text,\n",
    "                'match_term_list': list(df_ss['match_term'])[:5],\n",
    "                'identifier_list': list(df_ss['identifier'])[:5],\n",
    "                'similarity_list': list(df_ss['similarity'])[:5],\n",
    "                'match_type_list': list(df_ss['match_type'])[:5]\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(term, text, e)\n",
    "df_final = pd.DataFrame(data=final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('2_results_0712.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bbcc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: select top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4662e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a2e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68677cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check NaN\n",
    "import os\n",
    "for f in os.listdir('data/term_matching_csv/'):\n",
    "    if f.endswith('.csv'):\n",
    "        fpath = f'data/term_matching_csv/{f}'\n",
    "        check = pd.read_csv(fpath)\n",
    "        count_nan_in_df = check.isnull().sum().sum()\n",
    "        count_nan2_in_df = check.isna().sum().sum()\n",
    "        print (f, 'Count of NaN: ' + str(count_nan_in_df), str(count_nan2_in_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5442475",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_csv('data/9_GF_SYN_TS_mkd_docparse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f4568",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c67d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "check[~check.match_term.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40437cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e99b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "results = []\n",
    "path = \"data/evaluation/20230712/\"\n",
    "for f in os.listdir(path):\n",
    "    if re.search('FA.csv', f):\n",
    "        df = pd.read_csv(f'{path}/{f}', encoding='utf8')\n",
    "        clf = ['TP', 'FP', 'TN', 'FN']\n",
    "        TP = len(df[df.judge_all=='TP'])\n",
    "        FP = len(df[df.judge_all=='FP'])\n",
    "        TN = len(df[df.judge_all=='TN'])\n",
    "        FN = len(df[df.judge_all=='FN'])\n",
    "        if TP + FP > 0:\n",
    "            precision = TP / (TP + FP)\n",
    "        else:\n",
    "            precision = ''\n",
    "        if TP + FN > 0:\n",
    "            recall = TP / (TP + FN)\n",
    "        else:\n",
    "            recall = ''\n",
    "        results.append({\n",
    "            'fname': f,\n",
    "            'TP': TP,\n",
    "            'FP': FP,\n",
    "            'TN': TN,\n",
    "            'FN': FN,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ffd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18288af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(results_df.TP) / (sum(results_df.TP) + sum(results_df.FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62570c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate based on fa_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64888acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_identifier_type(fa_identifier):\n",
    "    idf_type = ''\n",
    "    if isinstance(fa_identifier, str):\n",
    "        if re.search('Cl_1.1\\-', fa_identifier, re.I):\n",
    "            idf_type = 'definition'\n",
    "        else:\n",
    "            if re.search('Cl', fa_identifier, re.I):\n",
    "                idf_type = 'clause'\n",
    "            elif re.search('Parties', fa_identifier, re.I):\n",
    "                idf_type = 'parties'\n",
    "            elif re.search('sched', fa_identifier, re.I):\n",
    "                idf_type = 'schedule'\n",
    "            else:\n",
    "                pass\n",
    "    return idf_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b050227",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sample\n",
    "\n",
    "path = 'data/evaluation/20230712/'\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if re.search('FA.csv', file):\n",
    "        df = pd.read_csv(os.path.join(path, file))\n",
    "        df['filename'] = file\n",
    "        df['identifier_type'] = df['fa_identifier'].apply(\n",
    "            lambda i: match_identifier_type(i)\n",
    "        )\n",
    "        df_s = df[['filename', 'fa_identifier', 'identifier_type', 'judge_all']]\n",
    "        df_all = df_all.append(df_s)\n",
    "        \n",
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e42635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.identifier_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2487f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for idf in set(df_all.identifier_type):\n",
    "    TP = len(df_all[(df_all.identifier_type==idf)&(df_all.judge_all=='TP')])\n",
    "    FP = len(df_all[(df_all.identifier_type==idf)&(df_all.judge_all=='FP')])\n",
    "    TN = len(df_all[(df_all.identifier_type==idf)&(df_all.judge_all=='TN')])\n",
    "    FN = len(df_all[(df_all.identifier_type==idf)&(df_all.judge_all=='FN')])\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else ''\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else ''\n",
    "    results.append({\n",
    "        'annotation_type': idf,\n",
    "        'TP': TP,\n",
    "        'FP': FP,\n",
    "        'TN': TN,\n",
    "        'FN': FN,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca546f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67568e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3972fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0712\n",
    "\n",
    "pd.DataFrame(data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5aa39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
